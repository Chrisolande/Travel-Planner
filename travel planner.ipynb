{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "cb0ee"
   },
   "source": [
    "# 1. Imports & Environment Setup\n",
    "\n",
    "- **Core Imports:**\n",
    "  - `os`, `warnings`, `datetime`, `uuid`, `string`, `random`, `hashlib`, `traceback`.\n",
    "\n",
    "- **LangChain/LangGraph Imports:**\n",
    "  - `ChatOpenAI`, `StreamingStdOutCallbackHandler`, `TavilySearch`, `TavilySearchResults`, agent/graph/integration tools, message types.\n",
    "\n",
    "- **Notebook & Display:**\n",
    "  - `clear_output`, `Markdown` from `IPython.display`.\n",
    "\n",
    "- **Environment:**\n",
    "  - Suppresses TensorFlow warnings.\n",
    "  - Loads environment variables (e.g., API keys) using `python-dotenv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellUniqueIdByVincent": "d3c1b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from typing import TypedDict, Dict, List\n",
    "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
    "from datetime import datetime\n",
    "from IPython.display import clear_output, Markdown\n",
    "import traceback\n",
    "import uuid\n",
    "import string\n",
    "import random\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca198beb",
   "metadata": {
    "cellUniqueIdByVincent": "6db79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def get_api_key(key_name=\"OPENROUTER_API_KEY\"):\n",
    "    \"\"\"\n",
    "    Get API key from environment variables\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(key_name)\n",
    "    if not api_key:\n",
    "        raise ValueError(f\"Invalid API key: {key_name} not found in environment variables\")\n",
    "    return api_key\n",
    "\n",
    "def initialize_llm(model_name=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "                  temperature=0.4,\n",
    "                  use_streaming=True):\n",
    "    \"\"\"\n",
    "    Initialize LLM\n",
    "    \"\"\"\n",
    "    api_key = get_api_key()\n",
    "    callbacks = [StreamingStdOutCallbackHandler()]\n",
    "    llm = ChatOpenAI(\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "        streaming=use_streaming,\n",
    "        callbacks=callbacks,\n",
    "        openai_api_key=api_key,\n",
    "        openai_api_base=\"https://openrouter.ai/api/v1\"\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm = initialize_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellUniqueIdByVincent": "2bfe9"
   },
   "outputs": [],
   "source": [
    "def save_file(data, filename, uniqueness_method=\"uuid\"):\n",
    "\n",
    "    folder_name = \"Travel Plans\"  # Folder to store output files\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Creates the folder if it doesn't exist\n",
    "    \n",
    "    # Generate unique identifier based on selected method\n",
    "    if uniqueness_method == \"uuid\":\n",
    "        # Generate a UUID (universally unique identifier)\n",
    "        unique_id = str(uuid.uuid4())[:8]\n",
    "        \n",
    "    elif uniqueness_method == \"random_string\":\n",
    "        # Generate a random string of letters and digits\n",
    "        chars = string.ascii_letters + string.digits\n",
    "        unique_id = ''.join(random.choice(chars) for _ in range(8))\n",
    "        \n",
    "    elif uniqueness_method == \"hash\":\n",
    "        # Create a hash based on content and current time\n",
    "        content_hash = hashlib.md5((data + str(datetime.now())).encode()).hexdigest()[:8]\n",
    "        unique_id = content_hash\n",
    "        \n",
    "    elif uniqueness_method == \"counter\":\n",
    "        # Use an incrementing counter for files with the same base name\n",
    "        counter = 1\n",
    "        while True:\n",
    "            test_filename = f\"{filename}_{counter}.md\"\n",
    "            test_path = os.path.join(folder_name, test_filename)\n",
    "            if not os.path.exists(test_path):\n",
    "                unique_id = str(counter)\n",
    "                break\n",
    "            counter += 1\n",
    "            \n",
    "    elif uniqueness_method == \"datetime\":\n",
    "        # Original datetime method\n",
    "        unique_id = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        \n",
    "    else:\n",
    "        # Default to UUID if an invalid method is specified\n",
    "        unique_id = str(uuid.uuid4())[:8]\n",
    "    \n",
    "    # Create the final filename with the unique identifier\n",
    "    final_filename = f\"{filename}_{unique_id}.md\"\n",
    "    file_path = os.path.join(folder_name, final_filename)\n",
    "    \n",
    "    # Save the data to the file in the specified path\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(data)\n",
    "        print(f\"File '{file_path}' created successfully.\")\n",
    "    \n",
    "    # Return the full path of the saved file\n",
    "    return file_path\n",
    "\n",
    "def show_md_file(file_path):\n",
    "    with open(file_path, \"r\", encoding = \"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "a8cb3"
   },
   "outputs": [],
   "source": [
    "class PlannerState(TypedDict):\n",
    "    travel_preferences: Dict\n",
    "    destination_options: List[Dict]\n",
    "    selected_destination: Dict\n",
    "    budget_plan: Dict\n",
    "    itinerary: List[Dict]\n",
    "    bookings: Dict\n",
    "    feedback: Dict\n",
    "    final_trip: Dict\n",
    "    messages: List\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "069eb"
   },
   "outputs": [],
   "source": [
    "def input_collector(state: PlannerState) -> PlannerState:\n",
    "    \"\"\"Collects and organizes user's travel preferences.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Extract the latest human message\n",
    "    human_message = next((m for m in reversed(messages) if isinstance(m, HumanMessage)), None)\n",
    "    system_prompt = \"\"\"You are a travel input collector. Extract travel preferences from the user's message.\n",
    "    Include: destination interests, travel dates, budget range, number of travelers, \n",
    "    accommodation preferences, activity interests, and any special requirements.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content = system_prompt),\n",
    "        human_message\n",
    "    ])\n",
    "    \n",
    "    # Parse the response into structured travel preferences\n",
    "    preferences = {\n",
    "        \"raw_input\": human_message.content,\n",
    "        \"processed_preferences\": response.content,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Update state\n",
    "    state[\"travel_preferences\"] = preferences\n",
    "    state[\"messages\"].append(AIMessage(content=f\"I've collected your travel preferences. Moving on to destination research.\"))\n",
    "    state[\"status\"] = \"preferences_collected\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "c5044"
   },
   "outputs": [],
   "source": [
    "def destination_research(state: PlannerState) -> PlannerState:\n",
    "    \"\"\"Researches and suggests destinations based on user preferences\"\"\"\n",
    "    preferences = state[\"travel_preferences\"]\n",
    "    system_prompt = \"\"\"\n",
    "    You are a destination research expert. Based on the user's travel preferences, suggest \n",
    "    3-5 suitable destinations. For each destination, provide:\n",
    "    - Name and brief description\n",
    "    - Why it matches their preferences\n",
    "    - Best time to visit\n",
    "    - Estimated overall cost level\n",
    "    - Key attractions\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content = f\"Travel Preferences: {preferences}\")\n",
    "    ])\n",
    "    \n",
    "    # Process the response into structured destination options\n",
    "    destination_options = {\n",
    "        \"options\": response.content,\n",
    "        \"research_timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    # Update State\n",
    "    state[\"destination_options\"] = destination_options\n",
    "    state[\"messages\"].append(AIMessage(content=f\"I've researched some destinations that match your preferences. Moving on to budget planning.\"))\n",
    "    state[\"status\"] = \"awaiting_destination_selection\"\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "4a7dd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vincent": {
   "sessionId": "583bcb7e51bde3e5ae191216_2025-05-16T12-32-59-715Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
